{
  "content": "# A/B testing a payment method\n\n## Launch an A/B test for a new payment method in the Dashboard.\n\nA/B testing allows you to measure the impact of offering new payment methods to\na percentage of buyers before offering them to all of your customers. You can\nrun A/B tests without writing any code.\n\nUse A/B testing to:\n\n- Test Buy Now, Pay Later payment methods like Klarna, Affirm, and Afterpay with\na subset of customers before you introduce them to all of your customers.\n- Measure the impact of targeting rules, such as setting a minimum purchase\nprice for certain payment methods.\n- Gradually offer a new payment method to an increasing percentage of customers.\n\nYou need to use [Payment Element\nWeb](https://docs.stripe.com/payments/payment-element) or\n[Checkout](https://docs.stripe.com/payments/checkout) with [dynamic payment\nmethods](https://docs.stripe.com/payments/payment-methods/dynamic-payment-methods?payment-ui=payment-element#customization-features)\nto run an A/B test. See [Supported payment\nmethods](https://docs.stripe.com/payments/a-b-testing#supportability) for the\nlist of payment methods you can test.\n\n[Begin your A/B\nexperiment](https://docs.stripe.com/payments/a-b-testing#begin-ab-experiment)\n\n![A custom configuration page with the Create an experiment\nbutton](https://b.stripecdn.com/docs-statics-srv/assets/create-experiment.93f437615e14f46700ee3f66cfafb367.png)\n\n- In the Stripe Dashboard, open the [Payment method\nsettings](https://dashboard.stripe.com/settings/payment_methods), then click\n**Create an experiment**.- You can only start, stop, and manage an experiment\nusing the Stripe Dashboard (there’s no API option).\n- If you have more than one payment method configuration, select the\nconfiguration you want to run an experiment on before you click **Create an\nexperiment**. You can only run one experiment at a time per configuration.\n- Select which payment methods you want to include in the experiment.\n- *(Optional)* Add custom [payment method\nrules](https://docs.stripe.com/payments/payment-method-rules), such as\ntransaction amount or presentment currency, as additional filters to control\nwhen a payment method is eligible. You can also create custom rules using the\nstandalone feature.\n- Name your experiment and choose the percentage of traffic to include in your\ntreatment group.- **Traffic allocation**: Our default recommendation is 50% to\nbalance receiving results quickly (statistically significant results take longer\nwith a lower percentage) and risk management of poor experiment performance. You\ncan opt for a smaller or larger percentage based on your risk tolerance and\nexperiment goals. With an even 50/50 treatment/control split, a sample size of\n80,000 offers enough power to detect a 100 BPS change in the conversion rate at\na 5% significance level.\n- **Experiment randomization**: Stripe randomizes buyer sessions based on a\nunique identifier, which includes the\n[UserAgent](https://en.wikipedia.org/wiki/User-Agent_header), IP address, and\ndate. As a result, an individual buyer sees the same set of treatment or control\npayment method options for a particular day. To avoid instances of double\ncounting, such as page refreshes, we aggregate sessions for each unique user on\na daily basis.\n- Review and start your experiment. (You can save an experiment as a draft if\nyou’re not ready to start it.)\n#### Note\n\nWhen you begin an experiment, you can change the treatment group traffic\nallocation percentage but you can’t turn payment methods on or off for your\ncontrol or treatment groups. To make any payment method settings changes after\nan experiment has started, you must end the experiment first.\n- *(Recommended)* If you’re testing Buy Now, Pay Later (BNPL) payment methods,\nwe recommend that you install the [Payment Method Messaging\nElement](https://docs.stripe.com/payments/payment-method-messaging). This\nembeddable UI component allows your customers to see the available payment\noptions directly from your product, cart, or payment pages.\n[Manage and end an A/B\nexperiment](https://docs.stripe.com/payments/a-b-testing#manage-and-end-an-experiment)\n\n![A settings page to manage your\nexperiment](https://b.stripecdn.com/docs-statics-srv/assets/manage-experiment.25dc48d02e880cae44369eb82eaab30c.png)\n\n- To view all active and past experiments from your payment method settings,\nclick the overflow menu (), then select **Manage experiments**.\n- There are four actions you can take while an experiment is active. If you have\na Connect integration and select **treatment configuration**, any new payment\nmethod in treatment turns on for all users.- **Adjust traffic allocation**:\nAdjust the percentage of traffic allocated to your treatment group, which ranges\nfrom 1% to 99%.\n- **View experiment report**.\n- **Pause or resume an experiment**: When paused, only your control payment\nmethods are available to buyers and experiment data isn’t captured in your\nreport.\n- **End experiment**: When the experiment ends, you can either adopt your\ntreatment settings, or revert to your previous (control) settings. If your\nexperiment runs longer than 180 days, we end it on your behalf and enable your\ncontrol settings.\n[Understand your experiment\nresults](https://docs.stripe.com/payments/a-b-testing#understand-your-experiment)\nAfter your experiment begins, view its progress in the Stripe Dashboard.\n\n![A page with experiment\nresults](https://b.stripecdn.com/docs-statics-srv/assets/experiment-report.0d05f61a45c9a97306c62ffa616d4780.png)\n\nA/B testing considers an experiment complete when two conditions have been met:\n\n- Average revenue per session is [statistically\nsignificant](https://en.wikipedia.org/wiki/Statistical_significance). We\nconsider results to be statistically significant when there’s less than a 5%\nprobability that the result is due to a random chance. See [Experiment\nmethodology](https://docs.stripe.com/payments/a-b-testing#experiment-methodology).\n- The experiment has accrued enough sessions. This is a dynamic number based on\nthe treatment versus control percentage you set during experiment creation.\n\nExperiment result metrics include:\n\nResult metricDescriptionAverage revenue per sessionAverage revenue per session\nis the total revenue divided by the total number of sessions. It shows the\ndifference in revenue per session between your treatment and control groups, and\nis a summary of the overall results of your experiment. The total number of\nsessions includes both sessions that resulted in a purchase and sessions that\ndidn’t result in a purchase. Due to the significant variations in conversion\nrates and average order values by payment method, we recommend using the Average\nrevenue per session metric as a guiding metric when determining the overall\nsuccess of the experiment.Revenue at 100% of sessionsProjected total revenue if\nthe treatment group payment methods were offered to 100% of traffic across\ntreatment and control.Gross revenueActual revenue (full purchase amount). This\namount is influenced mainly by your treatment/control percentage\nselection.Conversion rateConversion rate is the number of sessions with a\npurchase divided by the total number of eligible sessions. Eligible sessions is\ndefined as:- One or more treatment payment methods was eligible (for example,\nthe buyer was in a country where the payment method is accepted)\n- The payment interface (Payment Element or Checkout) was rendered to the buyer\nAverage order valueAverage order value is the average purchase amount for\nsessions where the buyer made a purchase.\n### Statistical significance\n\nUse the indicators on the overview tables to understand statistical\nsignificance. The metrics display a green or yellow difference when the\nexperiment has reached at least 80% of estimated required sessions.\n\nThere are three types of indicators:\n\n- Gray indicators mean your experiment hasn’t accrued enough sessions to\nreliably determine statistical significance.\n- Green indicators demonstrate a statistically significant increase between the\ntreatment and control groups.\n- Yellow indicators demonstrate a statistically significant decrease between the\ntreatment and control groups.\n\n![A gray badge indicating there isn't statistical\nsignificance.](https://b.stripecdn.com/docs-statics-srv/assets/gray-indicator.5480d1fb0eab4d6a046c1bd10b5de350.png)\n\nBefore reaching statistical significance\n\n![A green badge indicating statistical\nsignificance.](https://b.stripecdn.com/docs-statics-srv/assets/green-indicator.2c1094ab3416c65174f86d0c24b27089.png)\n\nAfter reaching statistical significance\n\n### Conduct additional analysis\n\nYou can download raw data from the reporting page to further analyze your\nexperiment results.\n\nWe recommend grouping by `experiment_session_id` to avoid double counting\nsessions for instances such as a page refresh. This is consistent with how the\nA/B test report calculates average revenue per session, conversion rate, and\naverage order value.\n\nDimensionDescription`occurred_at_day`The day (‘yyyyMMdd’) of the\nsession.`experiment_session_id`A unique, Stripe-generated ID for each experiment\nsession. A session is based on the UserAgent, IP address, and\ndate.`is_treatment`A Boolean indicating whether outcome was assigned as\ntreatment (1) or control (0).`converted`A Boolean indicating whether this\nsession converted (1) or not (0).`payment_method`The actual payment method used\nfor the purchase.`converted_transaction_count`The number of individual\ntransaction-level conversions in the user session. Usually this value is either\n1 or 0, however, multiple conversions can occur within the same session if the\nsame buyer makes multiple purchases within the same\nday.`rendered_transaction_count`The number of individual transaction-level\nrenders in the user session. This can be a number >1 if a buyer visits the\npurchase page multiple times (for example, reloads or comes back later in the\nday).`amount_capturable`The total transaction amount.`currency`The currency type\nused in this transaction (for example, USD, GBP, EUR).`is_eligible_session`A\nBoolean indicating whether this session was eligible (1) or ineligible (0) for\nA/B testing. If this field returns a 0 (for example, no treatment payment\nmethods were eligible), then this session isn’t included in any reported metrics\nlike Average Order Value or Conversion Rate.`buyer_countries`The\ncountry/countries associated with the user session. In most cases this is a\nsingle country, but there could be multiple if the buyer is traveling or changes\ntheir browser’s location settings.`control_payment_method_types`The list of\ncontrol payment methods that were eligible to be shown in this\nsession.`treatment_payment_method_types`The list of treatment payment methods\nthat were eligible to be shown in this session.`rendered_payment_methods`The\nlist of payment methods that were available in the user session, including those\nhidden behind an overflow ‘show more’ selector.`visible_payment_methods`The list\nof payment methods that were visible in the user session (not hidden behind an\noverflow, such as ‘show more’).`connected_account_id`The connected account ID\nassociated with the session.\n### Experiment methodology\n\nA/B testing measures the [average treatment\neffect](https://en.wikipedia.org/wiki/Average_treatment_effect) (ATE) by\ncomparing treatment and control outcomes. We consider an experiment\nstatistically significant when there’s less than a 5% probability that the\nresult is due to a random chance. In statistical terms, we use a\n[z-test](https://en.wikipedia.org/wiki/Z-test) to calculate differences between\nthe treatment and control group at the 5% level, which is mechanically the same\nas checking whether the 95% confidence interval for the difference includes 0.\nTo determine how many sessions are required to detect an impact, we run a power\ncalculation based on your selected treatment and control percentage split. This\npower calculation returns the number of sessions required to have 80% power to\ndetect a 1% difference between treatment and control at a 5% significance level.\n\n#### Note\n\nTo provide you with this A/B testing service we need to derive analytics\nregarding your customers’ activities from your transaction data. We use your\ncustomers’ IP address and User Agent information to identify when a user who was\nshown a payment method on one page of the checkout flow went on to complete the\nflow. Depending on the law applicable to you and your customers, instructing us\nto undertake this activity on your behalf might require you to take steps such\nas providing disclosures and collecting customers’ consent to this activity.\nConsult with your legal counsel to make sure that you’re complying with all of\nyour obligations under applicable data protection laws.\n\n## Supported payment methods\n\n### Integration options\n\nYou can access A/B testing if your integration uses [Payment Element\nWeb](https://docs.stripe.com/payments/payment-element) or\n[Checkout](https://docs.stripe.com/payments/checkout) with [dynamic payment\nmethods](https://docs.stripe.com/payments/payment-methods/dynamic-payment-methods?payment-ui=payment-element#customization-features).\n\n### Supported payment methods\n\n### A/B testing for Connect Connect\n\nA/B testing is available for Connect platforms, but not for individual connected\naccounts. When setting up an A/B test, the payment methods selected for control\nand treatment apply to all eligible connected accounts. To opt out specific\nconnected accounts, you can specify a list of account IDs during the experiment\ncreation process.\n\nPlatforms can allow connected accounts to customize their payment method\nsettings to turn on or off specific payment methods. If a connected account\nturns on or off any payment method that’s in a treatment or control group, the\nconnected account’s preference applies to both treatment and control sessions.\nFor example, if a platform runs an experiment with Klarna on, and a connected\naccount has turned off Klarna, Klarna is never shown as an available payment\nmethod for the connected account’s users.\n\n## Links\n\n- [Payment Element Web](https://docs.stripe.com/payments/payment-element)\n- [Checkout](https://docs.stripe.com/payments/checkout)\n- [dynamic payment\nmethods](https://docs.stripe.com/payments/payment-methods/dynamic-payment-methods?payment-ui=payment-element#customization-features)\n- [Supported payment\nmethods](https://docs.stripe.com/payments/a-b-testing#supportability)\n- [Payment method\nsettings](https://dashboard.stripe.com/settings/payment_methods)\n- [payment method rules](https://docs.stripe.com/payments/payment-method-rules)\n- [UserAgent](https://en.wikipedia.org/wiki/User-Agent_header)\n- [Payment Method Messaging\nElement](https://docs.stripe.com/payments/payment-method-messaging)\n- [statistically\nsignificant](https://en.wikipedia.org/wiki/Statistical_significance)\n- [Experiment\nmethodology](https://docs.stripe.com/payments/a-b-testing#experiment-methodology)\n- [average treatment\neffect](https://en.wikipedia.org/wiki/Average_treatment_effect)\n- [z-test](https://en.wikipedia.org/wiki/Z-test)",
  "metadata": {
    "title": "A/B testing a payment method | Stripe Documentation",
    "description": "Launch an A/B test for a new payment method in the Dashboard.",
    "sourceURL": "https://docs.stripe.com/payments/a-b-testing"
  }
}